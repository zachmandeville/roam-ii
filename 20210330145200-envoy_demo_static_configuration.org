#+title: envoy demo static configuration
#+PROPERTY: header-args:yaml+  :noweb yes :tangle no :comments none

My annotated understanding of a demo configuration.
* Envoy Version
Importantly: this is for *envoy version 1.17.1*.
* Structure
The config is made up of [[file:20210323093747-listener.org][Listener]] and [[file:20210323093925-cluster.org][cluster]]
The envoy config is made up of a set of resources, namely [[file:20210323093747-listener.org][listeners]] and [[file:20210323093925-cluster.org][clusters]].  It can be dynamically configured (through a [[file:20210322103752-control_plane.org][Control Plane]]) or statically configured (e.g. through a file like the one we'll be making).  Even in a dynamic configuration, you'll still have a set of static resources, so that envoy knows where to get it's initial configuration from...and from that point youc an be ful dynamic.

Since this is a static config, we'll just be outlining a list of static_resources. We'll also set up an admin config, so we can view our stats in a web view.

So the basic structure of a config file is


#+NAME: envoy configuration structure
#+BEGIN_SRC yaml :tangle ~/Learning/envoy/configs/static-demo.yaml
static_resources:
  <<Listeners setup>>
  <<Clusters setup>>
# admin:
#   <<Admin setup>>
#+END_SRC
* Listeners
** Basic structure
The [[file:20210323093747-listener.org][listeners]] are sort of the entrance into the proxy. A listener is bound to a
port on a [[file:20210323092943-host.org][Host]], and /listens/ for incoming requests to that port. It then moves
these requests through a a chain of filters before it moves on to a cluster set
to manage that particualr type of request. Where it should go and what the
request data should look like is determined and perhaps altered through the
filter chain.

In other words, the listener part is quite straightforward, but you can pack a
lot of punch (and complexity) through the filters.

So a basic listener setup, for a single listener could look like so:

#+NAME: Listeners setup
#+BEGIN_SRC yaml
listeners:
- name: listener_0
  <<Listener address>>
  <<Filter chains>>
#+END_SRC

The name is some unique name that is meaningful for you-- this will make it
easier to observe and debug later. If you don't provide one, envoy
will assign a unique UUID fos this listener for you.
** Address

The address can either be for a [[file:20210330151520-socket.org][socket]] or a [[file:20210330151740-pipe.org][pipe]] . Since we are communicating
across hosts, we'll use a socket.

#+NAME: Listener address
#+BEGIN_SRC yaml
address:
  socket_address:
    address: 0.0.0.0
    port_value: 10000
#+END_SRC

So we'll be listening on localhost at port 10000. any other communication
going to this host on other ports will be ignored by envoy.

** Filter chains
This is the meat of the listeners. You can add multiple filters to a listener,
that will process/redirect/calculate/observe/etc. the incoming request data.

Each chain can have a filter match set for it, to determine whether the type of
request should move through this filter. If nothing is set, then all requests to
this port will move through this filter.

In our case we only hae a single filter set, the [[https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/network/http_connection_manager/v3/http_connection_manager.proto.html?highlight=http_connection_manager][http_connection_manager]]. this
filter will take in a stream of raw bytes and convert them into http messages
and events. It can then handle logging, routing, and other http goodness.

#+Name: Filter chains
#+BEGIN_SRC yaml
filter_chains:
- filters:
  - name: envoy.filters.network.http_connection_manager
    <<http connection manager config>>
#+END_SRC

So we are using the http_connection_manager to take an incoming request to port
10000 and route it to the envoyproxy site.

The setup of the filter will be done as a typed config, meaning it can be
validated against a v. specific version of a schema.

*** http connection manager configuration
First we give the config a stat prefix, which is the human-readable name we'd
use to find it in our logs.

#+NAME: Stat prefix
#+BEGIN_SRC yaml
stat_prefix: ingress_http
#+END_SRC

The manager can also send out a number of access logs, multiple ones that could
be filtered for particular types of events going to particular logs. For us, we
want to have one access log that is just going to stdout, so this is just going
to the standard output of this process.

The access log is also typed, and also tied to an encoded schema

#+NAME: Access logs
#+BEGIN_SRC yaml
access_log:
- name: envoy.access_loggers.file
  typed_config:
    "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
    path: /dev/stdout
#+END_SRC

Now we get to the filter. This will be a route filter that will redirect all
domains sent to this port to go envoy proxy instead

#+NAME: http filters
#+BEGIN_SRC yaml
http_filters:
- name: envoy.filters.http.router
#+END_SRC

For the router filter, we want a routing table, which we set up with our routing
config. This routing config is given a name, and then a set of hosts we can send
it to, based on their match and where the request should be sent.

#+NAME: route config
#+BEGIN_SRC yaml
route_config:
  name: local_route
  virtual_hosts:
  - name: local_service
    domains: ["*"]
    routes:
    - match:
        prefix: "/"
      route:
        host_rewrite_literal: www.envoyproxy.io
        cluster: service_envoyproxy_io
#+END_SRC

the name we know. The virtual hosts are a list of hosts with a domain and a
route...in this case we want a wildcard domain...so no matter what is coming to
the port, go to the first host called 'local_service'. The route is oging to
match anything that starts with '/'

for this route, we want to send it to our cluster (defined below) called
service_envoy_proxy_io...but rewrite the host header during the forwarding to be
'www.envoyproxy.io'. The cluster itself will direct to the actual site, this is
just adjusting the header.

So all together, we have a filter that is structured like so

#+NAME: http connection manager config
#+BEGIN_SRC yaml
typed_config:
  "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
  <<Stat prefix>>
  <<Access logs>>
  <<HTTP filters>>
  <<Route config>>
#+END_SRC

* Clusters

Clusters are the other main element of an envoy configuration. The listener
takes in, processes, and directs data to the right cluster. Clusters are
services that _do_ soemthing with the correct, incoming data.

In our case, we only have a single cluster, we named ~service_envoyproxy_io~.

The cluster setup, in the end, will look like so:

#+NAME: Clusters setup
#+BEGIN_SRC yaml
clusters:
- name: service_envoyproxy_io
  <<Connect timeout>>
  <<Service discovery type>>
  <<Load assignment>>
  <<Transport socket>>
#+END_SRC

each section we will detail below
** Connect timeout
How long for new networks to wait for a respone from this host before we timeout.  We'll set it for 30s.
#+NAME: Connect timeout
#+BEGIN_SRC yaml
connect_timeout: 30s
#+END_SRC

** Service discovery type
Simply called type in the config, this is a [[file:20210323094240-service_discovery.org][service discovery]] type to be used by
this cluster. Logical DNS is a good match as it allows for a dns lookup with
multiple hosts that can remain up and running until they are cycled through.

When using LOGICAL_DNS, we can set whether we want ipv4, ipv6, or auto (try for 6 before settling for 4)

#+NAME: Service discovery type
#+BEGIN_SRC yaml
type: LOGICAL_DNS
dns_lookup_family: V4_ONLY
#+END_SRC
** Load assignment

Next we set up our load_assignment, in previous versions this was called  ~hosts~.

#+NAME: Load assignment
#+BEGIN_SRC yaml
load_assignment:
  cluster_name: service_envoy_proxy_io
  endpoints:
  - lb_endpoints:
    - endpoint:
        address:
          socket_address:
            address: www.envoyproxy.io
            port_value: 443
#+END_SRC

There's a lot of yaml nesting, but the idea is fairly straightforward. In our
http filter chain, it took all requests and forwarded them with a modified
header to a cluster named ~service_envoyproxy_io~. We defined the cluster here,
but a cluster could be made up of multiple hosts, all performing the same
logical service. Here in our load_assignment, we list the endpoints and their
addresses so the load balancer knows where it can direct the request, following
your load balancing policy.

In this case, we only have one endpoint: a remote server we find by dns
at ~www.envoyproxy.io~
** Transport socket
for the last part of our cluster setup, we set our transport socket. This is a
custom transport socket, if we don't include this, envoy will use a default,
based on platform and context. In this case, we want to use UpstreamTlsContext,
so that our upstream connections are encrypted, instead of sent as plaintext.

We then set the sni we are using, which is the envoyproxy address.

#+NAME: Transport socket
#+BEGIN_SRC yaml
transport_socket:
  name: envoy.transport_sockets.tls
  typed_config:
    "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
    sni: www.envoyproxy.io
#+END_SRC


All in all, a lot of words to handle a redirect...but it's also foundational to
setup a whole bunch of _other_ stuff, in the same way, too.

* Admin

The last bit of config is to set up an admin interface. We can use this to
investigate the logs, see what's running, etc.  This isn't working for 1.17.1, but is in latest, so am holding off for now.

#+NAME: Admin setup
#+BEGIN_SRC yaml
access_log_path: /tmp/envoy-demo/access.log
address:
socket_address:
    address: 0.0.0.0
    port_value: 9901
#+END_SRC

We will bind the interface to 9901, viewable at ~localhost:9901~.  The default config puts all access logs to /dev/null (e.g. deletes them).  I'll set ours to ~/tmp/envoy-demo/access.log~ to parse them later

#+NAME: envoy demo configuration
#+BEGIN_SRC yaml

static_resources:

  listeners:
  - name: listener_0
    address:
      socket_address:
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          access_log:
          - name: envoy.access_loggers.stdoutput
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.access_loggers.stdoutput.v3.StdoutputAccessLog
          http_filters:
          - name: envoy.filters.http.router
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: ["*"]
              routes:
              - match:
                  prefix: "/"
                route:
                  host_rewrite_literal: www.envoyproxy.io
                  cluster: service_envoyproxy_io

  clusters:
  - name: service_envoyproxy_io
    connect_timeout: 30s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    load_assignment:
      cluster_name: service_envoyproxy_io
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.envoyproxy.io
                port_value: 443
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: www.envoyproxy.io

admin:
  access_log_path: /dev/null
  address:
    socket_address:
      address: 0.0.0.0
      port_value: 9901
#+END_SRC
